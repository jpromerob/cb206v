{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING ORIGINAL DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "original_dataset = pd.read_csv(\"datasets/original_dataset.txt\", delimiter='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_dataset = original_dataset\n",
    "\n",
    "# Replace '.' with 0 in the entire DataFrame\n",
    "clean_dataset.replace('.', 0, inplace=True)\n",
    "\n",
    "# For Column FGRStrand\n",
    "clean_dataset.replace('+', 1, inplace=True)\n",
    "clean_dataset.replace('-', -1, inplace=True)\n",
    "\n",
    "# Remove the prefix from column 'peakName'\n",
    "clean_dataset['peakName'] = clean_dataset['peakName'].str.replace('chm13v2_accessible_region_', '', regex=False)\n",
    "\n",
    "# Get unique values from the 'region' column and create a map string:index\n",
    "region_dict = {region: index for index, region in enumerate(clean_dataset['region'].unique())}\n",
    "\n",
    "# Replace the strings in the 'region' column with their corresponding indices\n",
    "clean_dataset['region'] = clean_dataset['region'].map(region_dict)\n",
    "\n",
    "# Dropping 'FGR' 'cause it seems that it has weird data\n",
    "clean_dataset = clean_dataset.drop(columns=['FGR'])\n",
    "\n",
    "# Dropping 'FGR' 'cause it seems that it has weird data\n",
    "clean_dataset = clean_dataset.drop(columns=['chr'])\n",
    "\n",
    "# Remove rows where FGRstart<0\n",
    "clean_dataset = clean_dataset[clean_dataset['FGRstart'] >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['peakStart', 'peakEnd', 'peakName', 'peakScore', 'FGRstart', 'FGRend',\n",
      "       'FGRstrand', 'region'],\n",
      "      dtype='object')\n",
      "Unique regions and their assigned indices:\n",
      "{'promoter': 0, 'enhancer': 1, 'divergent': 2, 'geneBody': 3, 'CPS': 4, 'TW': 5, 'untranscribed': 6}\n"
     ]
    }
   ],
   "source": [
    "nb_ATAC_seq_rows = 7\n",
    "\n",
    "#These are the columns NOT linked to a protein\n",
    "print(clean_dataset.columns[:nb_ATAC_seq_rows+1])\n",
    "\n",
    "\n",
    "# Print the dictionary of unique regions and their indices\n",
    "print(\"Unique regions and their assigned indices:\")\n",
    "print(region_dict)\n",
    "\n",
    "with open('region_dict.json', 'w') as file:\n",
    "    json.dump(region_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Protein Names from Column Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract column names from the 11th column to the last\n",
    "protein_run_set = clean_dataset.columns[nb_ATAC_seq_rows+1:]\n",
    "\n",
    "# Extract the protein names (second part of the string) using a list comprehension\n",
    "proteins = list([col.split('_')[1] for col in protein_run_set])\n",
    "\n",
    "\n",
    "# # Count occurrences of each unique protein\n",
    "protein_count = Counter(proteins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing sets of proteins that occur 2, 3 or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 89 unique proteins that occur more than 1 times\n",
      "{'AFF1': 2, 'ARNT': 3, 'ATF3': 3, 'BCLAF1': 2, 'CBX3': 2, 'CEBPB': 2, 'CHAMP1': 2, 'CSDE1': 2, 'CTCF': 5, 'DPF2': 2, 'E2F1': 2, 'E2F6': 2, 'EGR1': 3, 'ELF1': 2, 'EP300': 2, 'ETV6': 2, 'FOXK2': 2, 'GATA1': 2, 'GATA2': 2, 'GTF2F1': 3, 'H3K27me3': 3, 'H3K36me3': 2, 'H3K4me1': 2, 'H3K4me3': 4, 'H3K9ac': 2, 'HDAC1': 4, 'HDAC2': 4, 'HDGF': 2, 'IKZF1': 2, 'JUN': 2, 'KDM1A': 3, 'KDM4B': 2, 'LEF1': 2, 'MAX': 3, 'MCM2': 2, 'MCM5': 2, 'MCM7': 3, 'MITF': 2, 'MLLT1': 2, 'MNT': 3, 'MTA2': 2, 'MYC': 3, 'NCOA1': 3, 'NCOA2': 2, 'NCOR1': 4, 'NFATC3': 2, 'NFE2': 2, 'NFRKB': 2, 'NONO': 2, 'NR3C1': 2, 'NRF1': 4, 'POLR2A': 6, 'POLR2AphosphoS2': 2, 'RAD21': 2, 'RCOR1': 2, 'REST': 3, 'RFX1': 2, 'RNF2': 5, 'RUNX1': 2, 'SETDB1': 2, 'SIN3A': 2, 'SIRT6': 2, 'SIX5': 2, 'SMARCA4': 3, 'SP1': 2, 'SUZ12': 2, 'TAL1': 2, 'TARDBP': 3, 'TBL1XR1': 2, 'TCF12': 2, 'TRIM24': 2, 'TRIM25': 2, 'TRIM28': 3, 'UBTF': 2, 'YY1': 3, 'ZBTB33': 2, 'ZBTB5': 2, 'ZC3H8': 2, 'ZEB2': 2, 'ZMIZ1': 2, 'ZNF184': 2, 'ZNF24': 3, 'ZNF274': 2, 'ZNF316': 2, 'ZNF318': 2, 'ZNF407': 2, 'ZNF639': 2, 'ZNF830': 2, 'ZSCAN29': 2}\n",
      "There are 25 unique proteins that occur more than 2 times\n",
      "{'ARNT': 3, 'ATF3': 3, 'CTCF': 5, 'EGR1': 3, 'GTF2F1': 3, 'H3K27me3': 3, 'H3K4me3': 4, 'HDAC1': 4, 'HDAC2': 4, 'KDM1A': 3, 'MAX': 3, 'MCM7': 3, 'MNT': 3, 'MYC': 3, 'NCOA1': 3, 'NCOR1': 4, 'NRF1': 4, 'POLR2A': 6, 'REST': 3, 'RNF2': 5, 'SMARCA4': 3, 'TARDBP': 3, 'TRIM28': 3, 'YY1': 3, 'ZNF24': 3}\n",
      "There are 8 unique proteins that occur more than 3 times\n",
      "{'CTCF': 5, 'H3K4me3': 4, 'HDAC1': 4, 'HDAC2': 4, 'NCOR1': 4, 'NRF1': 4, 'POLR2A': 6, 'RNF2': 5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_protein_histogram(proteins, bar_width=0.4):\n",
    "    # Count occurrences of each unique protein\n",
    "    protein_count = Counter(proteins)\n",
    "\n",
    "    # Create a dictionary of proteins that occur more than once\n",
    "    dict_list = []\n",
    "    for i in [1, 2, 3]:\n",
    "        dict_list.append({protein: count for protein, count in protein_count.items() if count > i})\n",
    "        filename = f\"proteins_occ_more_than_{i}.png\"\n",
    "\n",
    "        # Set up the figure with the specified size\n",
    "        num_proteins = len(dict_list[i-1])\n",
    "        plt.figure(figsize=(8, num_proteins * bar_width * 0.6))  # Adjust the height based on number of proteins\n",
    "\n",
    "        # Create the histogram (note the order of x and y)\n",
    "        plt.barh(list(dict_list[i-1].keys()), list(dict_list[i-1].values()), color='skyblue', height=bar_width)\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.ylabel('Proteins')\n",
    "        plt.xlabel('Number of Occurrences')\n",
    "        plt.title(f'Histogram of Proteins Occurring More Than {i} times')\n",
    "        plt.ylim(-0.5, num_proteins - 0.5)  # Adjust the limits to remove extra space\n",
    "\n",
    "        # Save the plot as a PNG file\n",
    "        plt.tight_layout()  # Adjust layout to fit labels\n",
    "        plt.savefig(f'images/other/{filename}')  # Save the figure\n",
    "        # plt.show()\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "\n",
    "        print(f'There are {len(dict_list[i-1])} unique proteins that occur more than {i} times')\n",
    "        print(dict_list[i-1])\n",
    "\n",
    "\n",
    "\n",
    "plot_protein_histogram(proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Proteins that only occur once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "Original #Columns: 458\n",
      "Final #Columns: 223\n"
     ]
    }
   ],
   "source": [
    "# Listing proteins that occur only once (less than 2 times)\n",
    "less_than_2 = {protein: count for protein, count in protein_count.items() if count < 2}\n",
    "print(len(less_than_2))\n",
    "\n",
    "# Creating a copy of the dataset that only keeps proteins that occur more than once\n",
    "dataset_more_than_1 = clean_dataset\n",
    "print(f'Original #Columns: {dataset_more_than_1.shape[1]}')\n",
    "\n",
    "for protein in less_than_2:\n",
    "    columns_to_drop = dataset_more_than_1.filter(like=f'{protein}').columns\n",
    "    dataset_more_than_1.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f'Final #Columns: {dataset_more_than_1.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Dataset: keeping rows where 'peakScore' is within one STDEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest peakScore: 104617\n",
      "Lowest peakScore: 13\n",
      "Mean peakScore: 198.0256167094002\n",
      "Stdev peakScore: 540.4664950452996\n",
      "Dataset reduced from 85413 to 81357 rows\n",
      "That reduction means that ~95% of the data has been kept\n"
     ]
    }
   ],
   "source": [
    "highest_peak_score = dataset_more_than_1['peakScore'].max()\n",
    "print(f'Highest peakScore: {highest_peak_score}')\n",
    "\n",
    "lowest_peak_score = dataset_more_than_1['peakScore'].min()\n",
    "print(f'Lowest peakScore: {lowest_peak_score}')\n",
    "\n",
    "mean_peak_score = dataset_more_than_1['peakScore'].mean()\n",
    "print(f'Mean peakScore: {mean_peak_score}')\n",
    "\n",
    "stdv_peak_score = dataset_more_than_1['peakScore'].std()\n",
    "print(f'Stdev peakScore: {stdv_peak_score}')\n",
    "\n",
    "\n",
    "# Define the bounds for peakScore within 3 standard deviations\n",
    "threshold = 1\n",
    "lower_bound = 0\n",
    "upper_bound = mean_peak_score + threshold * stdv_peak_score\n",
    "\n",
    "# Filter the dataset to keep only the rows within these bounds\n",
    "filtered_dataset = dataset_more_than_1[(dataset_more_than_1['peakScore'] >= lower_bound) & (dataset_more_than_1['peakScore'] <= upper_bound)]\n",
    "\n",
    "print(f'Dataset reduced from {dataset_more_than_1.shape[0]} to {filtered_dataset.shape[0]} rows')\n",
    "print(f'That reduction means that ~{int(100*filtered_dataset.shape[0]/dataset_more_than_1.shape[0])}% of the data has been kept')\n",
    "\n",
    "# Plot the histogram of the 'peakScore' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_dataset['peakScore'], bins=100, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of Peak Score', fontsize=16)\n",
    "plt.xlabel('Peak Score', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('images/other/PeakScoreDistribution.png')  # Save the figure\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Storing filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset has only 36% of original cells\n",
      "Filtered dataset has only 34% of original cells\n"
     ]
    }
   ],
   "source": [
    "original_cell_count = original_dataset.shape[0]*original_dataset.shape[1]\n",
    "clean_cell_count = clean_dataset.shape[0]*clean_dataset.shape[1]\n",
    "\n",
    "print(f'Clean dataset has only {int(100*clean_cell_count/original_cell_count)}% of original cells')\n",
    "\n",
    "original_cell_count = original_dataset.shape[0]*original_dataset.shape[1]\n",
    "filtered_cell_count = filtered_dataset.shape[0]*filtered_dataset.shape[1]\n",
    "\n",
    "print(f'Filtered dataset has only {int(100*filtered_cell_count/original_cell_count)}% of original cells')\n",
    "filtered_dataset.to_csv(\"datasets/filtered_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
